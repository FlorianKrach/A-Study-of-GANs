# A-Study-of-GANs
Code accompanying my master's thesis. 

## List of Python files with description
### JL-SWG and JL-SWGAN
- __JL_reconstruction.py__: code to test the encoding and decoding of image data with a Johnson-Lindenstrauss map and its pseudo-inverse
- __JLSWG_mnist.py__: code to train a JL-SWG (that means without discriminator) model or its SWG counterpart on enlarged versions of the MNIST dataset
- __JLSWG_toy_example.py__: code to train a JL-SWG model and its SWG counterpart on the toy dataset
- __JLSWG.py__: code to train a JL-SWG model and its SWG counterpart on different datasets
- __old_JLSWG.py__: code to train a JL-SWG model and its SWG counterpart on the standard MNIST dataset (28x28), JLSWG.py is suggested to be used instead (which will use a 32x32 version of MNIST)
- __JLSWGAN.py__: code to train a JL-SWGAN (that means with discriminator) model or its SWG counterpart on different datasets
- __result_plots.py__: code to make plots of the sliced Wasserstein distance (SWD) respectively the Inception Score (IS) that was recorded during training of the different JL-SWG and JL-SWGAN models. Also has a function to compare the training times.


### DCGAN with fixed weights
- __perturb_GAN.py__: code to load a trained DCGAN or WGAN-GP model, to perturb its weights multiple times and to compute the pixel-wise distances between the samples generated before and after perturbation. Generated samples are stored whenever a higher pixel-wise error is observed then before.
- __perturbed_pretrained_network_mnist.py__: code to load a pretrained model (trained e.g. with _training_mnist_partly_fixed.py_) for the MNIST dataset, perturb its weights and retrain some layers afterwards
- __training_mnist_partly_fixed.py__: code to train a DCGAN or WGAN-GP model where some of the layers are fixed during training (fixed layers can be chosen by user)
- __training_mnist_partly_fixed2.py__: updated version of _training_mnist_partly_fixed.py_ with more flexibility to choose the trainable layers
- __training_subset_numbers_mnist.py__: code to train a DCGAN or WGAN-GP model on a subset of the MNIST dataset and to retrain only some of the layers afterwards on either the complementary subset or the entire dataset


### General purpose
- __celeba_preprocessing.py__: code to preprocess the CelebA dataset, i.e. to cut out the wanted part of the pictures and to save them as numpy-array
- __celeba.py__: code to load the numpy-arrays of the CelebA data, e.g. during training
- __cifar10.py__: code to load the the CIFAR-10 data, e.g. during training
- __compute_IS.py__: code to compute the Inception Score (IS) of a trained model
- __inception_score.py__: code to compute the Inception Score (IS), used in the training process of a model
- __layer_statistics.py__: code to compute the statistics of the weights of each layer of a (trained) GAN and to plot histograms of them. Statistics are saved as .csv and .excel files.
- __mnist.py__: code to load the MNIST dataset, e.g. during training
- __preprocessing_mnist.py__: code to artificially enlarge the MNIST data, save it as numpy-array or as gzip of a pickled numpy-array and also to load this dataset (e.g. during training)
- __pretrained_models__: a directory containing a pre-trained DCGAN model for the MNIST dataset, which was used in our experiments
- __save_images.py__: code to save numpy-arrays that are generated by GANs as .png image files
- __send_email.py__: code to send emails with attechments (used for training on cluster)
- __settings.py__: settings for the different files and hyper-parameter-arrays for parallel testing, contains the hyper-parameters that were discussed in the master thesis



